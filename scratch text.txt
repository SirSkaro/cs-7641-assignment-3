#Part 1:
Metrics to explore:
- inter- and intra-cluster distances
- silloette score
Think about the density/separation of clusters

#Part 2:
Pair-wise plots

metrics:
	PCA: distribution of Eignvalues (or surregate metrics, e.g., explained variance)
	ICA: Kurtosis
	RP: reconstruction
	Wall clock time

------------------------ K-Means Clustering --------------------------
import numpy as np
import kmc
from data_utils import Task
import data_utils

(k, clustering, avg_score, score), all_avg_scores = kmc.find_k(Task.LETTER_RECOGNITION, kmc.MeanInit.KM_PP, trials_per_k=2)

letter_sample_set = data_utils.get_all_samples(Task.LETTER_RECOGNITION)
letter_clusters, letter_analysis = kmc.cluster(letter_sample_set, k=26, init=kmc.MeanInit.KM_PP, trials=5)

scribe_sample_set = data_utils.get_all_samples(Task.SCRIBE_RECOGNITION)
scribe_clusters, scribe_analysis = kmc.cluster(scribe_sample_set, k=13, init=kmc.MeanInit.KM_PP, trials=5)

silhouette, homogeneity, completeness, v_measure = kmc.evaluate_clustering(Task.LETTER_RECOGNITION, 450)

"""
# silloette scores:
# letter: 
	176: 0.1931728701901657 | completeness: 0.4356951219636452 | homogeneity: 0.6796690349100583 | v_measure: 0.5309987437467609
	200; 0.19084691036698107  | completeness: 0.44018072013264326 | homogeneity: 0.7054080230190843 | v_measure: 0.5420915898765245
	450: 0.2020981461244021 (best) | completeness: 0.4458824349673295 | homogeneity: 0.8252565553595167 | v_measure: 0.5789569908194494
	
# scribe:
	2: 0.9905801808292309 (best) | completeness: 1.0 |  homogeneity: 0.0 | v_measure: 0.0
	3: 0.5884568207764931 | completeness: 0.017136526219465608 |  homogeneity: 0.003733116286206823 | v_measure: 0.006130689119519832
	4: 0.1727682678671664 | completeness: 0.06354217853255736 |  homogeneity: 0.027765711424748596 | v_measure: 0.038644936231902786
	2500: 0.1597032308800456 | completeness: 0.17003526729821233 |  homogeneity: 0.6884730180965728 | v_measure: 0.27271651456648555
	5000: 0.1656511552757454 | completeness: 0.17636063310585565 |  homogeneity: 0.7867585086731617 | v_measure: 0.28813305160713715
"""

------------------------ EM Clustering --------------------------
import numpy as np
import em
from data_utils import Task
import data_utils

em.create_graph(Task.LETTER_RECOGNITION)
em.create_graph(Task.SCRIBE_RECOGNITION)


# BIC:
# letter:
	2: 1210906
	140: 682616 (best)
	1000: 1352947
	2000: 1928724
	3000: 2803573
	4000: 3929766
# scribe:
	180: -100133
	550: -130361 (best)
	
------------------------ PCA --------------------------
import numpy as np
import pca
from data_utils import Task
import data_utils

task = Task.LETTER_RECOGNITION
sample_set = data_utils.get_all_samples(task)
model, transformed_data = pca.transform(sample_set, 3)


------------------------ ICA --------------------------
import numpy as np
import ica
from data_utils import Task
import data_utils
import scipy.stats as stats


letter_kurtosis_scores = ica.graph_analysis(Task.LETTER_RECOGNITION)
scribe_kurtosis_scores = ica.graph_analysis(Task.SCRIBE_RECOGNITION)

sample_set = data_utils.get_all_samples(Task.LETTER_RECOGNITION)
best, averages = ica.choose_num_components(sample_set)

------------------------ RP --------------------------
import numpy as np
import rp
from data_utils import Task
import data_utils

letter_best, letter_mean_errors, letter_pca_errors = rp.graph_analysis(Task.LETTER_RECOGNITION, 5)
scribe_best, scribe_mean_errors, scribe_pca_errors = rp.graph_analysis(Task.SCRIBE_RECOGNITION, 5)

------------------------ kPCA --------------------------
import numpy as np
import k_pca
from data_utils import Task
import data_utils

sample_set, test_set = data_utils.get_training_and_test_sets(Task.LETTER_RECOGNITION, 0.05)
model, transformed_data = k_pca.transform(sample_set, 'rbf', 3)

k_pca.plot_3d(Task.LETTER_RECOGNITION, ['sigmoid', 'rbf', 'poly'], 0.8)


------------------------ part 3 --------------------------
import numpy as np
from data_utils import Task
import data_utils
import em
import ica
import kmc
import k_pca
import pca
import rp
import part3

silhouette_scores, homogeneity_scores, completeness_scores, v_measure_scores = part3.pca_km(Task.LETTER_RECOGNITION)

------------------------ part 4 --------------------------
import data_utils
from data_utils import Task, SampleSet
import k_pca
import neural_network as nn

task = Task.LETTER_RECOGNITION
original_samples = data_utils.get_all_samples(task)
reduction_model, transformed_samples = k_pca.transform(original_samples, 'cosine', 6)

original_training, original_test = data_utils.get_training_and_test_sets(task, 0.7, randomize=True)
reduced_training = SampleSet(reduction_model.transform(original_training.samples), original_training.labels)
reduced_test = SampleSet(reduction_model.transform(original_test.samples), original_test.labels)

classifier, test_error, train_error, validation_error = nn.learn(reduced_training, reduced_test, hidden_layers=6, units_per_hidden_layer=7, optimizer=nn.Optimizer.ADA_DELTA)

