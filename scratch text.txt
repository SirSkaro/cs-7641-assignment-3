#Part 1:
Metrics to explore:
- inter- and intra-cluster distances
- silloette score
Think about the density/separation of clusters

#Part 2:
Pair-wise plots


------------------------ K-Means Clustering --------------------------
import numpy as np
import kmc
from data_utils import Task
import data_utils

(k, clustering, avg_score, score), all_avg_scores = kmc.find_k(Task.LETTER_RECOGNITION, kmc.MeanInit.KM_PP, trials_per_k=2)

letter_sample_set = data_utils.get_all_samples(Task.LETTER_RECOGNITION)
letter_clusters, letter_analysis = kmc.cluster(letter_sample_set, k=26, init=kmc.MeanInit.KM_PP, trials=5)

scribe_sample_set = data_utils.get_all_samples(Task.SCRIBE_RECOGNITION)
scribe_clusters, scribe_analysis = kmc.cluster(scribe_sample_set, k=13, init=kmc.MeanInit.KM_PP, trials=5)

"""
# silloette scores:
# letter: 
	200; 0.19084691036698107
	176: 0.1931728701901657
	
# scribe:
	2: 0.9905801808292309
	3: 0.5884568207764931
	4: 0.1727682678671664
	5000: 0.1656511552757454
"""

------------------------ EM Clustering --------------------------
import numpy as np
import em
from data_utils import Task
import data_utils

em.create_graph(Task.LETTER_RECOGNITION)
em.create_graph(Task.SCRIBE_RECOGNITION)


# BIC:
# letter:
	2: 1210906
	140: 682616
	1000: 1352947
	2000: 1928724
	3000: 2803573
	4000: 3929766
# scribe:
	180: -100133
	550: -130361